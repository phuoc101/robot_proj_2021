{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3e14883",
   "metadata": {},
   "source": [
    "# Exercise 4 -Computer Vision \n",
    "## Task 4 - Face Detection and Tracking\n",
    "\n",
    "\n",
    "- [x] First import the required python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ed45085",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T21:16:22.871173Z",
     "start_time": "2021-10-11T21:16:22.763783Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import time\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d053d029",
   "metadata": {},
   "source": [
    "\n",
    "- [x] Read the OpenCV [documentation](https://docs.opencv.org/master/db/d28/tutorial_cascade_classifier.html) on Cascade classifiers which implements Viola-Jones detection algorithm. Instatntiate the cascade classifier for finding faces.\n",
    "- [x] Assign variables for fps control, points collections and image collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14a1a919",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T21:16:26.329596Z",
     "start_time": "2021-10-11T21:16:26.307988Z"
    }
   },
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "frame_rate = 30\n",
    "prev = 0\n",
    "gray_prev = None\n",
    "p0 = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb82336",
   "metadata": {},
   "source": [
    "Complete the function which performs following\n",
    "- [x] Takes a frame from video feed as the input\n",
    "- [ ] Resize the frame while protecting the aspect ratio (width = 600) \n",
    "- [ ] Flip the image\n",
    "- [ ] Convert the frame to grayscale image\n",
    "- [x] Return grayscale image and resized image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7b95762",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T21:16:27.518655Z",
     "start_time": "2021-10-11T21:16:27.514294Z"
    }
   },
   "outputs": [],
   "source": [
    "def prep(img):\n",
    "    # Your code begins here\n",
    "    img = imutils.resize(img, width = 600)\n",
    "    img = cv2.flip(img, 1)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Your code ends here\n",
    "    return gray, img    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96848eab",
   "metadata": {},
   "source": [
    "Complete the function which perfoms following\n",
    "- [x] Takes grayscale image and resized image as the input\n",
    "- [x] Detect faces in graycale image using cascade classifier. [detectMultiscale()](https://docs.opencv.org/3.4/d1/de5/classcv_1_1CascadeClassifier.html) function returns detected faces as rectangles ( Top left x coordinate, Top left y coordinate, width, height)\n",
    "- [ ] Draw a rectangle around detected faces using OpenCV drawing [functions](https://docs.opencv.org/4.5.2/dc/da5/tutorial_py_drawing_functions.html)\n",
    "- [ ] Slice a region of interest (ROI) from grayecale image corresponding to the detections\n",
    "- [x] Extract good features to track, from OpenCV [goodFeaturesToTrack()](https://docs.opencv.org/4.5.2/d4/d8c/tutorial_py_shi_tomasi.html) function.\n",
    "- [ ] The points are located with respect to the ROI. Convert them to image coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21d3e53b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T21:16:28.650296Z",
     "start_time": "2021-10-11T21:16:28.643465Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_trackable_points(gray,img, p0):\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n",
    "    if len(faces) != 0:\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "            roi_gray = gray[y:y+h,x:x+w]\n",
    "    \n",
    "        p0 = cv2.goodFeaturesToTrack(roi_gray,maxCorners=70,qualityLevel=0.001,minDistance=5)\n",
    "        \n",
    "        # Your code begins here\n",
    "        for p in p0:\n",
    "            p[0,0] += x\n",
    "            p[0,1] += y\n",
    "\n",
    "        # Your code ends here\n",
    "   \n",
    "    return p0, faces, img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f6c1c4",
   "metadata": {},
   "source": [
    "Complete the function which perfoms following\n",
    "\n",
    "- [x] Use [cv2.calcOpticalFlowPyrLK()](https://docs.opencv.org/4.5.3/d4/dee/tutorial_optical_flow.html) to calculate the optical flow for tracking\n",
    "- [ ] Select the valid points from p1. Note that  isFound == 1 for valid points \n",
    "- [ ] Return the valid points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6754539",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T21:16:29.774333Z",
     "start_time": "2021-10-11T21:16:29.768823Z"
    }
   },
   "outputs": [],
   "source": [
    "def do_track_face(gray_prev, gray, p0):\n",
    "    p1, isFound, err = cv2.calcOpticalFlowPyrLK(gray_prev, gray, p0, \n",
    "                                                            None,\n",
    "                                                            winSize=(31,31),\n",
    "                                                            maxLevel=10,\n",
    "                                                            criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 30, 0.03),\n",
    "                                                            flags=cv2.OPTFLOW_LK_GET_MIN_EIGENVALS,\n",
    "                                                            minEigThreshold=0.00025)\n",
    "    \n",
    "    #your code begins here\n",
    "    p1 = np.delete(p1, np.where(isFound == 0), 0)\n",
    "\n",
    "    #your code ends here\n",
    "    return p1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740edad5",
   "metadata": {},
   "source": [
    "Run the progromm\n",
    "- [ ] Enter the path to video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "844eda03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T21:17:30.124027Z",
     "start_time": "2021-10-11T21:17:03.058266Z"
    }
   },
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(\"./Face.mp4\")\n",
    "if not cam.isOpened():\n",
    "    raise Exception(\"Could not open camera/file\")\n",
    "\n",
    "while cam.isOpened:\n",
    "    time_elapsed = time.time() - prev\n",
    "    \n",
    "    if time_elapsed > 1./frame_rate:\n",
    "        \n",
    "        ret_val,img = cam.read()\n",
    "        \n",
    "        if not ret_val:\n",
    "            cam.set(cv2.CAP_PROP_POS_FRAMES, 0)  # restart video\n",
    "            gray_prev = None  # previous frame\n",
    "            p0 = []  # previous points\n",
    "            continue\n",
    "        \n",
    "        prev = time.time()\n",
    "        \n",
    "        gray, img = prep(img)\n",
    "\n",
    "        if len(p0) <= 10: \n",
    "            p0, faces, img = get_trackable_points(gray,img, p0)\n",
    "            gray_prev = gray.copy()\n",
    "        \n",
    "        else:\n",
    "            for (x,y,w,h) in faces:\n",
    "                cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "                p1 = do_track_face(gray_prev, gray, p0)\n",
    "            for i in p1:\n",
    "                cv2.drawMarker(img, (i[0,0], i[0,1]),[255,0,0],0)\n",
    "            p0 = p1\n",
    "                   \n",
    "        cv2.imshow('Video feed', img)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "              \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7156018",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "balltracker",
   "language": "python",
   "name": "balltracker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "229px",
    "left": "1499px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
