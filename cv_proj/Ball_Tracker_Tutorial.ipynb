{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ea11534",
   "metadata": {},
   "source": [
    "#   Exercise 4 - Computer Vision\n",
    "\n",
    "##  Task 3- Object Detection\n",
    "\n",
    "Before you begin this tutorial you have to complete the following tasks explained in the handout\n",
    "- [x] Setting up the gazebo simulation as a ROS package\n",
    "- [x] Setting up Conda environment to run this jupyter notebook\n",
    "\n",
    "### Part 1 - Detecting a simulated ball\n",
    "\n",
    "\n",
    "- Import the required python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6fb4ea6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T21:12:03.008895Z",
     "start_time": "2021-10-11T21:12:02.662857Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imutils\n",
    "import cv2\n",
    "import rospy\n",
    "from cv_bridge import CvBridge\n",
    "from sensor_msgs.msg import Image, CameraInfo\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bff61d6",
   "metadata": {},
   "source": [
    "- [ ] First make sure you have roslaunched gazebo world runing in the background\n",
    "- [x] Initialize a ros node by the name \"ball_tracker\". Follow the rospy [documentatiomn](http://wiki.ros.org/rospy/Overview/Initialization%20and%20Shutdown) to undestand the code line\n",
    "- [x] Create an object of cv_bridge class. \n",
    "- [ ] You will be converting the image frames from RGB to HSV color space. Understand the [HSV](https://en.wikipedia.org/wiki/HSL_and_HSV) colour space interpretation. Define the threshold (Upper and Lower)for simulated ball in HSV color space. Read the OpenCV [documentation](https://docs.opencv.org/3.4.6/de/d25/imgproc_color_conversions.html#color_convert_rgb_hsv) to understand about OpenCV color converstion from RGB/BGR to HSV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25718cbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T21:12:06.548033Z",
     "start_time": "2021-10-11T21:12:06.391076Z"
    }
   },
   "outputs": [],
   "source": [
    "rospy.init_node('ball_tracker')\n",
    "rate = rospy.Rate(0.5)\n",
    "bridge = CvBridge()\n",
    "\n",
    "## Your code begins here\n",
    "Lower = (40, 40, 40)   # Enter relevant values as (Hue, Saturation,Value)\n",
    "Upper = (70, 255, 255)\n",
    "## Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f24d6e",
   "metadata": {},
   "source": [
    "Complete the function to perfom following tasks\n",
    "- [ ] Grab a ROS image by subscribing to the camera topic '/camera1/image_raw'. Hint: you can use [rospy.wait_for_message()](https://docs.ros.org/en/diamondback/api/rospy/html/rospy.client-pysrc.html#wait_for_message) to receive one message from a topic\n",
    "- [ ] Convert the ROS image message to an OpenCV image (desired_encoding='rgb8') and return output using [CvBridge](http://wiki.ros.org/cv_bridge/Tutorials/ConvertingBetweenROSImagesAndOpenCVImagesPython)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5e8cdc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T21:12:09.026241Z",
     "start_time": "2021-10-11T21:12:09.022159Z"
    }
   },
   "outputs": [],
   "source": [
    "def grab_frame():\n",
    "    \n",
    "    ## Your code begins here \n",
    "    img_message = rospy.wait_for_message('/camera1/image_raw', Image, timeout=5)\n",
    "    frame = bridge.imgmsg_to_cv2(img_message, desired_encoding='rgb8')\n",
    "    ## Your code ends here\n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a15f63",
   "metadata": {},
   "source": [
    "Create a function to perform the following process on image\n",
    "- [ ] Resize the image with [imutils](https://www.pyimagesearch.com/2015/02/02/just-open-sourced-personal-imutils-package-series-opencv-convenience-functions/) while protecting the original aspect ratio. set image width to 600. \n",
    "- [ ]  Add gaussean blur to the image with OpenCV image [smoothing] (https://docs.opencv.org/4.5.2/d4/d13/tutorial_py_filtering.html)\n",
    "-  [ ] Convert image from RGB to HSV using OpenCV image [conversion](https://docs.opencv.org/3.4/d8/d01/group__imgproc__color__conversions.html#gga4e0972be5de079fed4e3a10e24ef5ef0aa4a7f0ecf2e94150699e48c79139ee12)\n",
    "-  [ ] Construct a mask for green color using OpenCV [thresholding](https://docs.opencv.org/3.4/da/d97/tutorial_threshold_inRange.html) functions\n",
    "-  [ ] Perform Erosion and Dialation on the image mask using OpenCV [Morphological](https://docs.opencv.org/3.4/db/df6/tutorial_erosion_dilatation.html) operationshttps://docs.opencv.org/3.4/db/df6/tutorial_erosion_dilatation.html\n",
    "-  [x] Return image mask and resized frame as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13ab489c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T21:12:11.135616Z",
     "start_time": "2021-10-11T21:12:11.129936Z"
    }
   },
   "outputs": [],
   "source": [
    "def prep(frame, lower, upper):\n",
    "    # Your code begins here\n",
    "    # resize to 600x600\n",
    "    frame = imutils.resize(frame, width = 600)\n",
    "    # apply gaussian blur\n",
    "    frame_blur = cv2.GaussianBlur(frame, (5,5), cv2.BORDER_DEFAULT)\n",
    "    # rgb 2 hsv\n",
    "    frame_HSV = cv2.cvtColor(frame_blur, cv2.COLOR_RGB2HSV)\n",
    "    # thresholding\n",
    "    mask = cv2.inRange(frame_HSV, lower, upper)\n",
    "    # erosion & dilation\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    mask = cv2.erode(mask, kernel, iterations=1)\n",
    "    mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "    #Your code ends here\n",
    "    return mask, frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6ce59f",
   "metadata": {},
   "source": [
    "-  [ ] Create a function to find contours in the mask image and return a tuple consisting of contour coordinates using OpenCV [contour](https://docs.opencv.org/4.5.0/d4/d73/tutorial_py_contours_begin.html) functiuons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18df1f6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T21:12:19.606847Z",
     "start_time": "2021-10-11T21:12:19.602871Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_cnts(mask):\n",
    "    ## Your code begins here \n",
    "    # find contour in mask\n",
    "    cnts = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    ## Your code ends here\n",
    "\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    return cnts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c359a1",
   "metadata": {},
   "source": [
    "-  [x] Assuming all the above functions are ciompleted, run the following code to view 3 orignal image frmae, image mask and tracking in 3 individual windows\n",
    "-  [x] Press \"Q\" to abort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba646531",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T21:12:27.769177Z",
     "start_time": "2021-10-11T21:12:21.357556Z"
    }
   },
   "outputs": [],
   "source": [
    "while not rospy.is_shutdown():\n",
    "    \n",
    "    frame = grab_frame()\n",
    "    mask, frame  = prep(frame, Lower, Upper)\n",
    "    \n",
    "    # Display the frame grabbed from ROS message\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    cv2.imshow(\"Mask\", mask)    \n",
    "   \n",
    "    cnts  = find_cnts(mask) \n",
    "    \n",
    "\n",
    "    center = None\n",
    "    # proceed only if a contour is detected\n",
    "    if len(cnts) > 0:\n",
    "        c = max(cnts, key=cv2.contourArea)\n",
    "        ((x, y), radius) = cv2.minEnclosingCircle(c)\n",
    "        # Find center of contour using moments in opencvq\n",
    "        M = cv2.moments(c)\n",
    "        center = (int(M[\"m10\"] / M[\"m00\"]), int(M[\"m01\"] / M[\"m00\"]))\n",
    "        if radius > 10:\n",
    "            cv2.circle(frame, (int(x), int(y)), int(radius),\n",
    "                (0, 0, 255), 2)\n",
    "            cv2.circle(frame, center, 5, (0, 0, 255), -1)\n",
    "\n",
    "    cv2.imshow(\"Tracking\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "cv2.destroyAllWindows()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fda2c7",
   "metadata": {},
   "source": [
    "### Part 2 - Detecting a coloured blob from a video\n",
    "\n",
    "\n",
    "-  [ ]  Now lets do the tracking of a blob in video file without using ROS. Have a look at the video file provided with the assignment folder. Initialize the new threshold values according to the color you want to detect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52d4d997",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T21:12:31.243312Z",
     "start_time": "2021-10-11T21:12:31.240671Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your code begins here\n",
    "Lower = (85, 50, 40)\n",
    "Upper = (160, 250, 255)\n",
    "# Your code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a19289e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T21:12:33.796116Z",
     "start_time": "2021-10-11T21:12:33.788046Z"
    }
   },
   "outputs": [],
   "source": [
    "def prep_video_frame(frame, lower, upper):\n",
    "    # Your code begins here\n",
    "    # resize to 600x600\n",
    "    # frame = imutils.resize(frame, width = 600)\n",
    "    # apply gaussian blur\n",
    "    # frame_blur = cv2.GaussianBlur(frame, (5,5), cv2.BORDER_DEFAULT)\n",
    "    # rgb 2 hsv\n",
    "    frame_HSV = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    # thresholding\n",
    "    mask = cv2.inRange(frame_HSV, lower, upper)\n",
    "    # erosion & dilation\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    mask = cv2.erode(mask, kernel, iterations=1)\n",
    "    mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "    #Your code ends here\n",
    "    return mask, frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0f5496",
   "metadata": {},
   "source": [
    "-  [ ] Complete the rest of the program to grab a frame from video clip and apply image processing functions to detect the color blob. You may reuse the functions from Part 1. You may also refer OpenCV documentation and implement new functions if you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "644b338b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T21:12:56.403023Z",
     "start_time": "2021-10-11T21:12:37.240560Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "vid = cv2.VideoCapture(\"./test_video.avi\")\n",
    "\n",
    "while vid.isOpened():\n",
    "    # capture video frame by frame\n",
    "    ret, frame = vid.read()\n",
    "    if ret == True:\n",
    "        time.sleep(0.05)\n",
    "        mask, frame  = prep_video_frame(frame, Lower, Upper)\n",
    "\n",
    "        cv2.imshow('frame', frame)\n",
    "        cv2.imshow('Mask', mask)\n",
    "        # press q to quit\n",
    "        cnts  = find_cnts(mask) \n",
    "        \n",
    "\n",
    "        center = None\n",
    "        # proceed only if a contour is detected\n",
    "        if len(cnts) > 0:\n",
    "            c = max(cnts, key=cv2.contourArea)\n",
    "            ((x, y), radius) = cv2.minEnclosingCircle(c)\n",
    "            # Find center of contour using moments in opencvq\n",
    "            M = cv2.moments(c)\n",
    "            center = (int(M[\"m10\"] / M[\"m00\"]), int(M[\"m01\"] / M[\"m00\"]))\n",
    "            if radius > 10:\n",
    "                cv2.circle(frame, (int(x), int(y)), int(radius),\n",
    "                    (0, 0, 255), 2)\n",
    "                cv2.circle(frame, center, 5, (0, 0, 255), -1)\n",
    "\n",
    "        cv2.imshow(\"Tracking\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9f3bc238adafcbda79d55911295148c0a733e591781969245cd9ef14f2888e84"
  },
  "kernelspec": {
   "display_name": "balltracker",
   "language": "python",
   "name": "balltracker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
